{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from redis import Redis\n",
    "\n",
    "REDIS = Redis(host='this_redis')\n",
    "mongo_client = pymongo.MongoClient('this_mongo')\n",
    "corpus_db = mongo_client.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_pickle('data/corpus.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df_records = corpus.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7ff8e00de750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_db.documents.drop()\n",
    "corpus_db.documents.insert_many(corpus_df_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_db.documents.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5a91c454ce14f80061525963'),\n",
       " 'sentence': 'In the great green room There was a telephone And a red balloon',\n",
       " 'title': 'Goodnight, Moon'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_db.documents.find_one({'tokens' : {'$exists': False}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `MAPPER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document):\n",
    "    return (document\n",
    "            .replace(',','')\n",
    "            .replace('.','')\n",
    "            .split())\n",
    "\n",
    "def MAPPER(document):\n",
    "    for word in tokenize(document):\n",
    "        yield (word, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 1),\n",
       " ('the', 1),\n",
       " ('great', 1),\n",
       " ('green', 1),\n",
       " ('room', 1),\n",
       " ('There', 1),\n",
       " ('was', 1),\n",
       " ('a', 1),\n",
       " ('telephone', 1),\n",
       " ('And', 1),\n",
       " ('a', 1),\n",
       " ('red', 1),\n",
       " ('balloon', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = corpus_db.documents.find_one({'tokens' : {'$exists': False}})\n",
    "list(MAPPER(doc['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_filter = {'processed' : {'$exists': False}}\n",
    "doc = corpus_db.documents.find_one(unprocessed_filter)\n",
    "while doc:\n",
    "    id_filter = { '_id' : doc['_id'] }\n",
    "    tokens = list(MAPPER(doc['sentence']))\n",
    "    update = { '$set' : {'tokens' : tokens, 'processed' : 'tokenized'} }\n",
    "    corpus_db.documents.update_one(id_filter, update)\n",
    "    doc = corpus_db.documents.find_one({'tokens' : {'$exists': False}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5a91c454ce14f80061525963'),\n",
       " 'processed': 'tokenized',\n",
       " 'sentence': 'In the great green room There was a telephone And a red balloon',\n",
       " 'title': 'Goodnight, Moon',\n",
       " 'tokens': [['In', 1],\n",
       "  ['the', 1],\n",
       "  ['great', 1],\n",
       "  ['green', 1],\n",
       "  ['room', 1],\n",
       "  ['There', 1],\n",
       "  ['was', 1],\n",
       "  ['a', 1],\n",
       "  ['telephone', 1],\n",
       "  ['And', 1],\n",
       "  ['a', 1],\n",
       "  ['red', 1],\n",
       "  ['balloon', 1]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_db.documents.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `COLLECTOR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def COLLECTOR(document, vocabulary):\n",
    "    for token in doc['tokens']:\n",
    "        REDIS.sadd(vocabulary, token[0])\n",
    "        REDIS.rpush(*token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5a91c454ce14f80061525963'),\n",
       " 'processed': 'tokenized',\n",
       " 'sentence': 'In the great green room There was a telephone And a red balloon',\n",
       " 'title': 'Goodnight, Moon',\n",
       " 'tokens': [['In', 1],\n",
       "  ['the', 1],\n",
       "  ['great', 1],\n",
       "  ['green', 1],\n",
       "  ['room', 1],\n",
       "  ['There', 1],\n",
       "  ['was', 1],\n",
       "  ['a', 1],\n",
       "  ['telephone', 1],\n",
       "  ['And', 1],\n",
       "  ['a', 1],\n",
       "  ['red', 1],\n",
       "  ['balloon', 1]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_filter = {'processed' : 'tokenized'}\n",
    "doc = corpus_db.documents.find_one(tokenized_filter)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "while doc:\n",
    "    id_filter = { '_id' : doc['_id'] }\n",
    "    tokens = doc['tokens']\n",
    "    update = { '$set' : {'processed' : 'counted'} }\n",
    "    COLLECTOR(doc, 'corpus_vocab')\n",
    "    corpus_db.documents.update_one(id_filter, update)\n",
    "    doc = corpus_db.documents.find_one(tokenized_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'year', b'you', b\"I've\", b'out', b'apples']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = REDIS.smembers('corpus_vocab')\n",
    "list(vocabulary)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'1', b'1']\n",
      "[b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1']\n",
      "[b'1', b'1', b'1', b'1', b'1']\n",
      "[b'1', b'1']\n",
      "[b'1', b'1', b'1', b'1', b'1', b'1']\n"
     ]
    }
   ],
   "source": [
    "for word in list(vocabulary)[:5]:\n",
    "    print(REDIS.lrange(word, 0, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `REDUCER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def REDUCER(word):\n",
    "    counts = [int(i) for i in REDIS.lrange(word, 0, -1)]\n",
    "    return sum(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_counts = []\n",
    "for word in vocabulary:\n",
    "    word_counts.append((word.decode(), REDUCER(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 98),\n",
       " ('the', 97),\n",
       " ('a', 56),\n",
       " ('And', 41),\n",
       " ('said', 31),\n",
       " ('to', 30),\n",
       " ('he', 30),\n",
       " ('was', 24),\n",
       " ('tree', 21),\n",
       " ('of', 20)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
